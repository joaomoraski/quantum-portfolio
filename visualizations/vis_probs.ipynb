{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 cases.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vis import load_json, compare_solutions, plot_objective_vs_budget\n",
    "\n",
    "# Define the lambda folders to check\n",
    "lambda_folders = {\n",
    "    0.001: \"lambda_0001\",\n",
    "    0.01: \"lambda_001\",\n",
    "    0.1: \"lambda_01\",\n",
    "    1.0: \"lambda_1\",\n",
    "    0.9: \"lambda_09\",\n",
    "    10.0: \"lambda_10\",\n",
    "    100.0: \"lambda_100\",\n",
    "    1000.0: \"lambda_1000\"\n",
    "}\n",
    "\n",
    "method = \"cmaes\"\n",
    "base_path = f\"../results/{method}_hubo_results/\"\n",
    "\n",
    "# Dictionary to store the best results and lambdas for each case\n",
    "data = {}\n",
    "best_lambdas = {}\n",
    "\n",
    "best_exact_data = {}\n",
    "best_exact_lambdas = {}\n",
    "\n",
    "# Process each lambda folder\n",
    "for lambda_val, lambda_folder in lambda_folders.items():\n",
    "    folder_path = os.path.join(base_path, lambda_folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Warning: Folder {folder_path} does not exist. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    files = [file for file in os.listdir(folder_path) if \"portfolio_optimization_\" in file]\n",
    "    \n",
    "    # Process each file\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        file_data = load_json(file_path)\n",
    "        \n",
    "        # For each case in the file\n",
    "        for case_id, case_data in file_data.items():\n",
    "            # Get expectation value\n",
    "            expectation_val = case_data['qaoa_solution'][\"final_expectation_value\"] #['objective_values'][-1]\n",
    "            \n",
    "            # If we haven't seen this case before, or if this result is better\n",
    "            if case_id not in data or expectation_val < data[case_id]['qaoa_solution'][\"final_expectation_value\"]: #['objective_values'][-1]:\n",
    "                data[case_id] = case_data\n",
    "                best_lambdas[case_id] = lambda_val\n",
    "\n",
    "data2 = load_json(\"../results/classical_unconstrained/filtered_portfolio_optimization_results.json\")\n",
    "data3 = load_json(\"../results/classical_constrained/filtered_portfolio_optimization_results.json\")\n",
    "data4 = load_json(\"../results/exact_eigensolver/filtered_portfolio_optimization_results.json\")\n",
    "\n",
    "print(f\"Loaded {len(data)} cases.\")\n",
    "nqubits = 15\n",
    "path = f\"./{nqubits}_qubits\"\n",
    "results = compare_solutions(data, data2, data3, data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing QAOA probability enhancement...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'n_qubits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 154\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnalyzing QAOA probability enhancement...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m analysis_df \u001b[38;5;241m=\u001b[39m analyze_qaoa_vs_random_probability(results)\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalyzed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(analysis_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cases across \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43manalysis_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_qubits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m different qubit counts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Generate plots and statistics\u001b[39;00m\n\u001b[1;32m    157\u001b[0m qubit_summary \u001b[38;5;241m=\u001b[39m plot_qaoa_enhancement(analysis_df)\n",
      "File \u001b[0;32m~/Desktop/quantum-portfolio/myenv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/quantum-portfolio/myenv/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'n_qubits'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_qaoa_vs_random_probability(results):\n",
    "    \"\"\"\n",
    "    Compare QAOA's most probable state to random sampling probability (1/2^n_qubits)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Dictionary containing case results with QAOA solutions\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame: Analysis results by qubit count\n",
    "    \"\"\"\n",
    "    \n",
    "    analysis_data = []\n",
    "    \n",
    "    for case_id, case_data in results.items():\n",
    "        # Skip if no QAOA solution or states_probs\n",
    "        if 'qaoa_solution' not in case_data or 'states_probs' not in case_data['qaoa_solution']:\n",
    "            continue\n",
    "            \n",
    "        # Get number of qubits\n",
    "        #n_qubits = case_data.get('n_qubits', case_data.get('hyperparams', {}).get('n_qubits', 0))\n",
    "        #if n_qubits == 0:\n",
    "        #    continue\n",
    "\n",
    "        n_qubits = case_data[\"n_qubits\"]\n",
    "            \n",
    "        # Get the states probabilities\n",
    "        states_probs = case_data['qaoa_solution']['states_probs']\n",
    "        \n",
    "        # Find the maximum probability\n",
    "        max_prob = max(states_probs)\n",
    "        \n",
    "        # Calculate random probability\n",
    "        random_prob = 1 / (2 ** n_qubits)\n",
    "        \n",
    "        # Calculate enhancement factor\n",
    "        enhancement_factor = max_prob / random_prob\n",
    "        \n",
    "        analysis_data.append({\n",
    "            'case_id': case_id,\n",
    "            'n_qubits': n_qubits,\n",
    "            'max_prob': max_prob,\n",
    "            'random_prob': random_prob,\n",
    "            'enhancement_factor': enhancement_factor,\n",
    "            'best_lambda': best_lambdas.get(case_id, 'unknown')\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(analysis_data)\n",
    "\n",
    "def plot_qaoa_enhancement(df):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing QAOA to random sampling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group by qubit count\n",
    "    qubit_stats = df.groupby('n_qubits').agg({\n",
    "        'enhancement_factor': ['mean', 'std', 'min', 'max', 'count'],\n",
    "        'max_prob': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    qubit_stats.columns = ['n_qubits', 'mean_enhancement', 'std_enhancement', \n",
    "                          'min_enhancement', 'max_enhancement', 'count',\n",
    "                          'mean_max_prob', 'std_max_prob']\n",
    "    \n",
    "    # Create comprehensive plot\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Enhancement factor by qubit count\n",
    "    ax1.bar(qubit_stats['n_qubits'], qubit_stats['mean_enhancement'], \n",
    "            yerr=qubit_stats['std_enhancement'], capsize=5,\n",
    "            color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    # Add horizontal line at y=1 (no enhancement)\n",
    "    ax1.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Random level')\n",
    "    \n",
    "    ax1.set_title('QAOA Enhancement over Random Sampling', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Number of Qubits', fontsize=12)\n",
    "    ax1.set_ylabel('Enhancement Factor (QAOA/Random)', fontsize=12)\n",
    "    ax1.set_yscale('log')  # Log scale since enhancement decreases exponentially\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add count annotations\n",
    "    for i, row in qubit_stats.iterrows():\n",
    "        ax1.annotate(f\"n={int(row['count'])}\", \n",
    "                    (row['n_qubits'], row['mean_enhancement']),\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 2. Individual data points with jitter\n",
    "    for n_qubits in df['n_qubits'].unique():\n",
    "        qubit_data = df[df['n_qubits'] == n_qubits]\n",
    "        x_jitter = np.random.normal(0, 0.1, size=len(qubit_data))\n",
    "        ax2.scatter(qubit_data['n_qubits'] + x_jitter, qubit_data['enhancement_factor'],\n",
    "                   alpha=0.6, s=50, edgecolors='black')\n",
    "    \n",
    "    # Add mean line\n",
    "    ax2.plot(qubit_stats['n_qubits'], qubit_stats['mean_enhancement'], \n",
    "             'r-o', linewidth=2, markersize=8, label='Mean enhancement')\n",
    "    ax2.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Random level')\n",
    "    \n",
    "    ax2.set_title('Enhancement Factor Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Number of Qubits', fontsize=12)\n",
    "    ax2.set_ylabel('Enhancement Factor (log scale)', fontsize=12)\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Maximum probability comparison\n",
    "    ax3.bar(qubit_stats['n_qubits'] - 0.2, qubit_stats['mean_max_prob'], \n",
    "            width=0.4, label='QAOA Max Prob', color='blue', alpha=0.7)\n",
    "    \n",
    "    # Calculate and plot random probabilities\n",
    "    random_probs = [1/(2**q) for q in qubit_stats['n_qubits']]\n",
    "    ax3.bar(qubit_stats['n_qubits'] + 0.2, random_probs, \n",
    "            width=0.4, label='Random Prob', color='red', alpha=0.7)\n",
    "    \n",
    "    ax3.set_title('Probability Comparison: QAOA vs Random', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Number of Qubits', fontsize=12)\n",
    "    ax3.set_ylabel('Probability (log scale)', fontsize=12)\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. Summary statistics table as text\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_text = \"Summary Statistics by Qubit Count:\\n\\n\"\n",
    "    summary_text += f\"{'Qubits':<8} {'Mean Enh.':<12} {'Max Enh.':<12} {'Cases':<8} {'Random Prob':<15}\\n\"\n",
    "    summary_text += \"-\" * 65 + \"\\n\"\n",
    "    \n",
    "    for _, row in qubit_stats.iterrows():\n",
    "        random_prob = 1/(2**row['n_qubits'])\n",
    "        summary_text += f\"{int(row['n_qubits']):<8} {row['mean_enhancement']:<12.2f} {row['max_enhancement']:<12.2f} {int(row['count']):<8} {random_prob:<15.2e}\\n\"\n",
    "    \n",
    "    ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, \n",
    "            fontsize=11, fontfamily='monospace', va='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{nqubits}_qubits_qaoa_enhancement_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return qubit_stats\n",
    "\n",
    "# Run the analysis\n",
    "print(\"Analyzing QAOA probability enhancement...\")\n",
    "analysis_df = analyze_qaoa_vs_random_probability(results)\n",
    "\n",
    "print(f\"\\nAnalyzed {len(analysis_df)} cases across {analysis_df['n_qubits'].nunique()} different qubit counts.\")\n",
    "\n",
    "# Generate plots and statistics\n",
    "qubit_summary = plot_qaoa_enhancement(analysis_df)\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\nDetailed Enhancement Analysis:\")\n",
    "print(\"=\"*60)\n",
    "for n_qubits in sorted(analysis_df['n_qubits'].unique()):\n",
    "    qubit_data = analysis_df[analysis_df['n_qubits'] == n_qubits]\n",
    "    random_prob = 1/(2**n_qubits)\n",
    "    \n",
    "    print(f\"\\n{n_qubits} Qubits (Random prob: {random_prob:.2e}):\")\n",
    "    print(f\"  Cases analyzed: {len(qubit_data)}\")\n",
    "    print(f\"  Mean enhancement: {qubit_data['enhancement_factor'].mean():.2f}x\")\n",
    "    print(f\"  Best enhancement: {qubit_data['enhancement_factor'].max():.2f}x\")\n",
    "    print(f\"  Worst enhancement: {qubit_data['enhancement_factor'].min():.2f}x\")\n",
    "    print(f\"  Mean max probability: {qubit_data['max_prob'].mean():.4f}\")\n",
    "    \n",
    "    # Show best case\n",
    "    best_case = qubit_data.loc[qubit_data['enhancement_factor'].idxmax()]\n",
    "    print(f\"  Best case: {best_case['case_id']} (Î»={best_case['best_lambda']}, {best_case['enhancement_factor']:.2f}x enhancement)\")\n",
    "\n",
    "# Overall summary\n",
    "print(f\"\\nOverall Summary:\")\n",
    "print(f\"Average enhancement across all cases: {analysis_df['enhancement_factor'].mean():.2f}x\")\n",
    "print(f\"Maximum enhancement observed: {analysis_df['enhancement_factor'].max():.2f}x\")\n",
    "print(f\"Cases with >2x enhancement: {len(analysis_df[analysis_df['enhancement_factor'] > 2])}/{len(analysis_df)} ({len(analysis_df[analysis_df['enhancement_factor'] > 2])/len(analysis_df)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
